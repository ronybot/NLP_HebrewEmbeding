{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1uJF9ZhKe3fEJUu4w8JCt_UCL-m6KNZEv",
      "authorship_tag": "ABX9TyM5S1STYDXbk87yEs0oKt3L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronybot/NLP_HebrewEmbeding/blob/master/Data_augmentation_resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oyVetDVQTsf5"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from PIL import Image\n",
        "import asyncio\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import csv\n",
        "\n",
        "\n",
        "# Load the trained model\n",
        "\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y5KODrtxbA2",
        "outputId": "6ceb76e0-30d0-4a72-f747-1cce037f5b6e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cairosvg\n"
      ],
      "metadata": {
        "id": "FWTm0z5Aauol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pillow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5z_YARUlmvaM",
        "outputId": "571740b2-29f3-4be4-87b9-a94aa0116c65"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install retrying\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4FOfTvvbmgT",
        "outputId": "f2015622-951e-4c62-97a3-18eb410d5bfd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting retrying\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying) (1.16.0)\n",
            "Installing collected packages: retrying\n",
            "Successfully installed retrying-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import cairosvg\n",
        "import xml.etree.ElementTree as ET\n",
        "import hashlib\n",
        "import aiohttp\n",
        "import asyncio\n",
        "from retrying import retry\n",
        "import re\n",
        "import base64\n",
        "import time\n",
        "import threading\n",
        "import pickle\n",
        "import io\n",
        "\n",
        "\n",
        "\n",
        "# Global variable to be shared across threads\n",
        "\n",
        "\n",
        "public_gatway = ['dweb.link','ipfs.io','cf-ipfs.com','gateway.pinata.cloud','cloudflare-ipfs.com']\n",
        "SVG_TYPE = 'image/svg+xml'\n",
        "GIF_TYPE = 'image/gif'\n",
        "TEXT_TYPE = 'text/'\n",
        "MP4_TYPE = 'video/mp4'\n",
        "\n",
        "class image_download_manager:\n",
        "    def __init__(self):\n",
        "        self.base46_svg_pattern = re.compile(r'^data:image/svg+xml;base64')\n",
        "        self.base46_str_svg_pattern = 'data:image/svg+xml;base64'\n",
        "        self.base46_str_svg_pattern = 'data:image/svg+xml;base64'\n",
        "        self.utf8_str_svg_pattern ='data:image/svg+xml;utf8'\n",
        "\n",
        "    def _hash_url(self,url):\n",
        "        # Create a new SHA-256 hash object\n",
        "        sha256 = hashlib.sha256()\n",
        "\n",
        "        # Update the hash object with the URL bytes\n",
        "        sha256.update(url.encode('utf-8'))\n",
        "\n",
        "        # Get the hexadecimal representation of the hash\n",
        "        hashed_url = sha256.hexdigest()\n",
        "\n",
        "        return hashed_url\n",
        "    def _is_svg(self, content):\n",
        "        \"\"\"\n",
        "        Check if the given content or file is in SVG format.\n",
        "        \"\"\"\n",
        "        if isinstance(content, bytes):\n",
        "            # Check if the content starts with '<?xml' (XML declaration)\n",
        "            return content.startswith(b'<?xml') and b'svg' in content.lower()\n",
        "        elif isinstance(content, str):\n",
        "            # Check if the content starts with '<?xml' (XML declaration)\n",
        "            return content.startswith('<?xml') and 'svg' in content.lower()\n",
        "        else:\n",
        "            return False  # Unsupported content type\n",
        "    def _is_svg_content(self, content):\n",
        "        try:\n",
        "            root = ET.fromstring(content)\n",
        "            return root.tag.lower() == \"{http://www.w3.org/2000/svg}svg\"\n",
        "        except ET.ParseError:\n",
        "            return False\n",
        "\n",
        "    async def _fetch_data(self, url):\n",
        "        # match = self.base46_svg_pattern.match(url)\n",
        "        match = url.startswith(self.base46_str_svg_pattern) | url.startswith(self.utf8_str_svg_pattern)\n",
        "        # encoded_data= None\n",
        "        if match:\n",
        "            data_index = url.find(',')\n",
        "            if(data_index != -1):\n",
        "                _data = url[data_index + 1:]\n",
        "                img_content = _data if url.startswith(self.utf8_str_svg_pattern) else base64.b64decode(_data)\n",
        "                im = Image.open(BytesIO(cairosvg.svg2png(img_content)))\n",
        "                # encoded_data = match.group(1)\n",
        "                # encoded_data =base64.b64decode(encoded_data, validate=True)\n",
        "                return (im, 200, SVG_TYPE)\n",
        "\n",
        "            return (None, 500, None)\n",
        "        _start = time.time()\n",
        "        timeout = aiohttp.ClientTimeout(total=15)\n",
        "        async with aiohttp.ClientSession(timeout=timeout) as session:\n",
        "            async with session.get(url) as response:\n",
        "                _end = time.time()\n",
        "\n",
        "                content = await response.read()\n",
        "                if  response.content_type.startswith(TEXT_TYPE) or response.content_type == MP4_TYPE:\n",
        "                    return (None, 500, response.content_type)\n",
        "                im = Image.open(BytesIO(cairosvg.svg2png(file_obj=BytesIO(content)))) if response.content_type == SVG_TYPE else Image.open(BytesIO(content))\n",
        "                return (im, response.status, response.content_type)\n",
        "\n",
        "    async def _download_image_management(self, image_url):\n",
        "        url=''\n",
        "        if image_url.startswith('ipfs://'):\n",
        "            for gatway in public_gatway:\n",
        "                url = image_url.replace('ipfs://', f'https://{gatway}/ipfs/')\n",
        "                try:\n",
        "                    content, status, contentType = await self._fetch_data(url)\n",
        "                    if status == 200:\n",
        "                        return content, contentType\n",
        "                except Exception as err:\n",
        "                    print(\"An error occurred while downloading IPFS image_url \" + image_url + \" \" +type(err).__name__  )\n",
        "                await asyncio.sleep(10)\n",
        "\n",
        "\n",
        "            return None, None\n",
        "        try:\n",
        "            _content, _status, _contentType = await self._fetch_data(image_url)\n",
        "            if _status == 200:\n",
        "                return _content, _contentType\n",
        "            else:\n",
        "                return None, None\n",
        "        except Exception as err:\n",
        "\n",
        "            return None, None\n",
        "\n",
        "    def gif_to_images(self, gif_img: Image, frame_index=0):\n",
        "    # Open the GIF file\n",
        "        with gif_img as img:\n",
        "            # Ensure the requested frame index is within the valid range\n",
        "            frame_index = min(max(frame_index, 0), img.n_frames - 1)\n",
        "\n",
        "            # Set the current frame to the requested frame\n",
        "            img.seek(frame_index)\n",
        "\n",
        "            # Convert the frame to RGB mode (optional, depending on your needs)\n",
        "            rgb_frame = img.convert(\"RGB\")\n",
        "\n",
        "            # Return the RGB frame as a PIL Image\n",
        "            return rgb_frame\n",
        "\n",
        "\n",
        "    @retry(stop_max_attempt_number=3, wait_exponential_multiplier=1000, wait_exponential_max=60000)  # Max 1 minute between retries\n",
        "    async def download_image(self,image_url, cache):\n",
        "      try:\n",
        "          img, contentType = await self._download_image_management(image_url)\n",
        "          if img is None:\n",
        "              return None\n",
        "          if contentType == GIF_TYPE:\n",
        "              img = self.gif_to_images(img)\n",
        "          return img\n",
        "\n",
        "      except Exception as err:\n",
        "\n",
        "             return None\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QXWcQo_Ba6hv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all files in the folder\n",
        "import os\n",
        "folder_path = \"/content/drive/My Drive/fake_nfts\"\n",
        "\n",
        "files = os.listdir(folder_path)\n",
        "\n",
        "# Print the list of files\n",
        "print(\"Files in the 'fake_nfts' folder:\")\n",
        "for file in files:\n",
        "    print(file)"
      ],
      "metadata": {
        "id": "b9WPSoyoXLRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def print_image_by_path(image_path):\n",
        "  image = Image.open(image_path)\n",
        "  image.show()\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')  # Hide axis\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def print_image(content):\n",
        "\n",
        "  plt.imshow(content)\n",
        "  plt.axis('off')  # Turn off axis\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Y_QFFCvpdvDD"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "import requests\n",
        "\n",
        "dataset = \"/content/drive/My Drive/fake_nfts/resnet50-dataset.csv\"\n",
        "\n",
        "with open(dataset, 'r', newline='') as csvfile:\n",
        "            csv_reader = csv.DictReader(csvfile)\n",
        "            for row in csv_reader:\n",
        "\n",
        "                image_url = row.get('imageUrl')\n",
        "                fake_image_url = row.get('fakeImageurl')\n",
        "                if fake_image_url:\n",
        "                  downloder = image_download_manager()\n",
        "                  filename = image_url.split('/')[-1]\n",
        "                  fake_filename = fake_image_url.split('/')[-1]\n",
        "\n",
        "\n",
        "                  fake_image =await downloder.download_image(fake_image_url, False)\n",
        "                  image = await downloder.download_image(image_url, False)\n",
        "\n",
        "                  file      =os.path.join(\"/content/drive/My Drive/fake_nfts/\", filename+\".png\")\n",
        "                  fake_file =os.path.join(\"/content/drive/My Drive/fake_nfts/\", fake_filename+\".png\")\n",
        "                  if not os.path.exists(file):\n",
        "                    print(\"saving \" + file)\n",
        "                    image.save(file,format=\"PNG\")\n",
        "                  if not os.path.exists(fake_file):\n",
        "                    print(\"saving fake \" + fake_file)\n",
        "                    fake_image.save(fake_file,format=\"PNG\")\n",
        "\n",
        "\n",
        "                  #print_image(image)\n"
      ],
      "metadata": {
        "id": "8alxMZTJZvIo"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def apply_blur(image, kernel_size=(25, 25)):\n",
        "    return cv2.GaussianBlur(image, kernel_size, 0)\n",
        "\n",
        "def remove_extension(filename):\n",
        "    return os.path.splitext(filename)[0]\n",
        "\n",
        "def apply_grayscale(image):\n",
        "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "def apply_rotation(image):\n",
        "    angle =random.uniform(-170, 170)\n",
        "    print(\"angle\" +angle)\n",
        "    height, width = image.shape[:2]\n",
        "    rotation_matrix = cv2.getRotationMatrix2D((width/2, height/2), angle, 1)\n",
        "    return cv2.warpAffine(image, rotation_matrix, (width, height))"
      ],
      "metadata": {
        "id": "z7EeSvHoyLou"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distinct_values = set()\n",
        "action = \"grayscale\"\n",
        "\n",
        "with open(dataset, 'r', newline='') as csvfile:\n",
        "            csv_reader = csv.DictReader(csvfile)\n",
        "            for row in csv_reader:\n",
        "\n",
        "                original_file_name= row.get('Image2_file')\n",
        "                if original_file_name not in distinct_values:\n",
        "                  image_path =os.path.join(\"/content/drive/My Drive/fake_nfts/\", original_file_name)\n",
        "                  distinct_values.add(original_file_name)\n",
        "                  image =cv2.imread(image_path)\n",
        "                  #print_image(image)\n",
        "                  new_file_name =remove_extension(original_file_name)+\"_\"+action+\".png\"\n",
        "                  if not os.path.exists(new_file_name):\n",
        "\n",
        "\n",
        "                    new_file_path = os.path.join(\"/content/drive/My Drive/fake_nfts/\", new_file_name)\n",
        "                    transformed_image = apply_grayscale(image)\n",
        "                    #print_image(transformed_image)\n",
        "                    cv2.imwrite(new_file_path, transformed_image)\n",
        "                    #cv2.imread('transformed_image',transformed_image)\n",
        "                    print(\",0.9,,9,\"+original_file_name+\",\"+new_file_name+\",\"+action)"
      ],
      "metadata": {
        "id": "6-IUqb7G6vX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distinct_values = set()\n",
        "\n",
        "with open(dataset, 'r', newline='') as csvfile:\n",
        "            csv_reader = csv.DictReader(csvfile)\n",
        "            for row in csv_reader:\n",
        "\n",
        "                original_file_name= row.get('Image2_file')\n",
        "                if original_file_name not in distinct_values:\n",
        "                  image_path =os.path.join(\"/content/drive/My Drive/fake_nfts/\", original_file_name)\n",
        "                  distinct_values.add(original_file_name)\n",
        "                  image =cv2.imread(image_path)\n",
        "                  new_file_name =remove_extension(original_file_name)+\"_blur.png\"\n",
        "                  if not os.path.exists(new_file_name):\n",
        "\n",
        "\n",
        "                    new_file_path = os.path.join(\"/content/drive/My Drive/fake_nfts/\", new_file_name)\n",
        "                    blurred_image = apply_blur(image)\n",
        "                    cv2.imwrite(new_file_path, blurred_image)\n",
        "                    image = cv2.imread(original_file_name)\n",
        "                    print(\",0.9,,9,\"+original_file_name+\",\"+new_file_name+\",blure\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ckjKu-BYcAtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymongo\n"
      ],
      "metadata": {
        "id": "fdCnMpTAQPOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FOlg1Xih103F"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L85P-vfEWpFA"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load the ResNet50 model with pre-trained weights\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n",
        "# Add a dense layer for classification\n",
        "x = base_model.output\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create the model to be trained\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze all layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Data preprocessing and augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,  # Added for additional transformation\n",
        "    brightness_range=[0.5, 1.5],  # Adjusting brightness\n",
        "    channel_shift_range=100.0,  # Random channel shifts\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Specify your data directory\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory='/content/drive/My Drive/fake_nfts',\n",
        "    target_size=(224, 224),  # Same as ResNet50 input size\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJSMK4PCXyys",
        "outputId": "4e086292-c6b3-4714-edec-816cea028026"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n",
            "Found 0 images belonging to 0 classes.\n"
          ]
        }
      ]
    }
  ]
}